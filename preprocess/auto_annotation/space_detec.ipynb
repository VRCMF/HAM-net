{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404c29c-86db-488e-8336-47d1bc67d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf35cf7-8f34-4b55-b133-61e49be41a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_tokens(input_path):\n",
    "  with open(input_path, 'r') as f:\n",
    "    out_str = f.readlines()\n",
    "    f.close()\n",
    "  origin = []\n",
    "  lemma = []\n",
    "  pos = []\n",
    "  idx = 0\n",
    "  while idx < len(out_str):\n",
    "    if out_str[idx].startswith(\"# text = \"):\n",
    "      idx += 1\n",
    "      lemma_tmp = []\n",
    "      pos_tmp = []\n",
    "      orig_tmp = []\n",
    "      while out_str[idx] != '\\n':\n",
    "        origi_i = out_str[idx].split('\\t')[1].lower()\n",
    "        lemma_i = out_str[idx].split('\\t')[2]\n",
    "        pos_tag = out_str[idx].split('\\t')[3]\n",
    "        #print(lemma_i)\n",
    "        orig_tmp.append(origi_i.replace('#', ''))\n",
    "        lemma_tmp.append(lemma_i.replace('#', ''))\n",
    "        pos_tmp.append(pos_tag)\n",
    "        idx += 1\n",
    "      origin.append(orig_tmp)\n",
    "      lemma.append(lemma_tmp)\n",
    "      pos.append(pos_tmp)\n",
    "    else:\n",
    "      idx += 1\n",
    "  return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336248c-9803-472e-839c-4f51d3ab3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'KIR'\n",
    "\n",
    "label_path = '../data/processed_data/{}/label.txt'.format(sets)\n",
    "txt_path = '../data/processed_data/{}/full_sample_anno.txt'.format(sets)\n",
    "write_text_path = '../data/weak_data/{}/full_text.txt'.format(sets)\n",
    "write_label_path = '../data/weak_data/{}/label.txt'.format(sets)\n",
    "lemma_path = '../data/lemma_data/{}/full_sample.conllu'.format(sets)\n",
    "label_list = []\n",
    "with open(label_path, 'r') as f:\n",
    "    for i in f.readlines():\n",
    "        label_list.append(i.strip().split(';'))\n",
    "\n",
    "token_list = []\n",
    "with open(txt_path, 'r') as f:\n",
    "    for i in f.readlines():\n",
    "        token_list.append(i.strip().split(';')) \n",
    "        \n",
    "lemma_list = []\n",
    "with open(lemma_path, 'r') as f:\n",
    "    lemma_list = lemma_tokens(lemma_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f8e8a-be2a-442d-925b-860a4f05f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lemma_list) == len(token_list)\n",
    "for i in range(len(token_list)):\n",
    "    assert len(lemma_list[i]) == len(token_list[i])\n",
    "    assert len(lemma_list[i]) == len(label_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7ad9b-fe8d-4b8a-b611-720fde7b0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_label_text(sets):\n",
    "    label_path = '../data/processed_data/{}/label.txt'.format(sets)\n",
    "    txt_path = '../data/processed_data/{}/full_sample_anno.txt'.format(sets)\n",
    "    write_text_path = '../data/weak_data/{}/full_text.txt'.format(sets)\n",
    "    write_label_path = '../data/weak_data/{}/label.txt'.format(sets)\n",
    "    lemma_path = '../data/lemma_data/{}/full_sample.conllu'.format(sets)\n",
    "    stop_words_path = '../data/weak_data/stop_words.txt'\n",
    "    label_list = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for i in f.readlines():\n",
    "            label_list.append(i.strip().split(';'))\n",
    "\n",
    "    token_list = []\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for i in f.readlines():\n",
    "            token_list.append(i.strip().split(';')) \n",
    "            \n",
    "    stop_list = []\n",
    "    with open(stop_words_path, 'r') as f:\n",
    "        for i in f.readlines():\n",
    "            stop_list.append(i.strip()) \n",
    "        f.close()\n",
    "\n",
    "    new_label_list = []\n",
    "    new_token_list = []\n",
    "    count = 0\n",
    "    for idx_1 in range(len(label_list)):\n",
    "        label_row = label_list[idx_1]\n",
    "        token_row = token_list[idx_1]\n",
    "        new_label_row = []\n",
    "        new_token_row = []\n",
    "        for idx_2 in range(len(label_row)):\n",
    "            label = label_row[idx_2]\n",
    "            token = token_row[idx_2]\n",
    "            if ' ' in token:\n",
    "                token_ = token.split(' ')\n",
    "                for j in range(len(token_)):\n",
    "                    if token_[j] in stop_list:\n",
    "                        new_label_row.append('O')\n",
    "                        count +=1\n",
    "                        #print('--')\n",
    "                    else:\n",
    "                        new_label_row.append(label)\n",
    "                new_token_row += token_\n",
    "            else:\n",
    "                if token in stop_list:\n",
    "                    new_label_row.append('O')\n",
    "                    count +=1\n",
    "                    #print('--')\n",
    "                else:\n",
    "                    new_label_row.append(label)\n",
    "                new_token_row.append(token)\n",
    "        assert len(new_label_row) == len(new_token_row)\n",
    "        new_label_list.append(new_label_row)\n",
    "        new_token_list.append(new_token_row)\n",
    "\n",
    "    flat_new_label_list = [i for item in new_label_list for i in item]\n",
    "    flat_new_token_list = [i for item in new_token_list for i in item]\n",
    "\n",
    "    txt_string = ''\n",
    "    label_string = ''\n",
    "    for i in range(len(flat_new_token_list)):\n",
    "        token = flat_new_token_list[i]\n",
    "        label = flat_new_label_list[i]\n",
    "\n",
    "        txt_string += token\n",
    "        txt_string += ' '\n",
    "        label_string += label\n",
    "        label_string += ' '\n",
    "        if token == '.':\n",
    "            txt_string += '\\n'\n",
    "            label_string += '\\n'\n",
    "\n",
    "    with open(write_text_path, 'w+') as f:\n",
    "        f.write(txt_string)\n",
    "        f.close()\n",
    "\n",
    "    with open(write_label_path, 'w+') as f:\n",
    "        f.write(label_string)\n",
    "        f.close()\n",
    "        \n",
    "    # check the length of labels and sequence\n",
    "    lb = []\n",
    "    tx = []\n",
    "    with open(write_text_path, 'r') as f:\n",
    "        for i in f.readlines():\n",
    "            lb.append(i.strip().split(' '))\n",
    "\n",
    "    with open(write_label_path, 'r') as f:\n",
    "        for i in f.readlines():\n",
    "            tx.append(i.strip().split(' ')) \n",
    "            \n",
    "    assert len(lb) == len(tx)\n",
    "    for i in range(len(lb)):\n",
    "        assert len(lb[i]) == len(tx[i])\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994ff77-da07-4407-854e-8b60732edbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'KIR'\n",
    "# KIR SAD RTG OPER LAH \n",
    "refine_label_text(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6247d-d07d-449d-9802-3584f48169e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'RTG'\n",
    "# KIR SAD RTG OPER LAH \n",
    "refine_label_text(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62eed3f-9ade-4773-a10a-b2c9fee2612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'SAD'\n",
    "# KIR SAD RTG OPER LAH \n",
    "refine_label_text(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea27a1f-7f7c-49ae-b2ca-4766ac9e42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'LAH'\n",
    "# KIR SAD RTG OPER LAH \n",
    "refine_label_text(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314770f-a68e-44f2-a8b0-64ff9b7d7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'OPER'\n",
    "# KIR SAD RTG OPER LAH \n",
    "refine_label_text(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742e764-1c39-4f0f-a482-bd72dfac3772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
