{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d932db24-0d9d-4efc-a041-6b3c50d568cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542065e4-9d1a-464b-a5df-2e4367362958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import davies_bouldin_score, normalized_mutual_info_score, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8945054-ceca-458b-90ca-f3e4fabcfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sampling(kmeans, label, reduced_fea, cluster_idx, num_samples):\n",
    "    incluster_dist_list = []\n",
    "    cluster_center = kmeans.cluster_centers_[label]\n",
    "    for idx in cluster_idx:\n",
    "        point = reduced_fea[idx]\n",
    "        dist = euclidean(point, cluster_center)\n",
    "        incluster_dist_list.append(dist)\n",
    "    normalizd_dist = np.array(incluster_dist_list)\n",
    "    inverse_norm_dist = 1/normalizd_dist\n",
    "    sampled_idx = np.random.choice(cluster_idx, num_samples, p=inverse_norm_dist/inverse_norm_dist.sum()) \n",
    "    \n",
    "    return sampled_idx, inverse_norm_dist/inverse_norm_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368a256-9974-421a-bcf7-e2c75ea22d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min_scaling(inputs):\n",
    "    return (inputs  - min(inputs)) /(max(inputs) - min(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b5c077-eeac-4225-aed1-7697440e6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_cluster_sample(sent_list, sets, kmeans, kmean_cluster, sample_per_cluster, reduced_fea):\n",
    "    sample_str = ''\n",
    "    p_str = ''\n",
    "    cluster_idx_str = ''\n",
    "    sample_list = []\n",
    "    prob_list = []\n",
    "    annotate_sent_list = []\n",
    "    un_annotate_sent_list = []\n",
    "    cluster_idx_list = []\n",
    "    \n",
    "    for i in range(kmean_cluster):\n",
    "        cluster_idx = np.where(kmeans.labels_ == i)[0].tolist() \n",
    "        # cluster_idx = np.where(kmeans.labels_ == 0)[0].tolist() \n",
    "        # sample = np.random.choice(cluster_idx, sample_per_cluster) \n",
    "        sample, p = cluster_sampling(kmeans, i, reduced_fea, cluster_idx, sample_per_cluster)\n",
    "        diff_idx = list(set(cluster_idx) - set(sample))\n",
    "        annotate_sent = []\n",
    "        un_annotate_sent = []\n",
    "        for j in sample:\n",
    "            annotate_sent.append(sent_list[j])\n",
    "            \n",
    "        for z in diff_idx:\n",
    "            un_annotate_sent.append(sent_list[z])\n",
    "            \n",
    "        sample_list += list(sample)\n",
    "        prob_list.append(';'.join([str(item) for item in list(p)]))\n",
    "        annotate_sent_list += list(annotate_sent) \n",
    "        un_annotate_sent_list += list(un_annotate_sent) \n",
    "        cluster_idx_list.append(';'.join([str(item) for item in cluster_idx]))\n",
    "        \n",
    "    df = pd.DataFrame({'index': sample_list, 'sent': annotate_sent_list})\n",
    "    df.to_csv('../../data/weak_data/{}/annotation.csv'.format(sets), index=False)\n",
    "    \n",
    "    df = pd.DataFrame({'index': cluster_idx_list, 'prob': prob_list})\n",
    "    df.to_csv('../../data/weak_data/{}/annotation_prob.csv'.format(sets), index=False)\n",
    "    \n",
    "    with open('../../data/weak_data/{}/annotation.txt'.format(sets), 'w') as f:\n",
    "        f.write('\\n'.join(annotate_sent_list))\n",
    "        f.close()\n",
    "        \n",
    "    with open('../../data/weak_data/{}/un_annotation.txt'.format(sets), 'w') as f:\n",
    "        f.write('\\n'.join(un_annotate_sent_list))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ce816-0133-49f4-a098-8d9da0c97aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sent_list(sets, pca_dim, kmean_cluster, sample_per_cluster):\n",
    "    input_text_path = '../../data/weak_data/{}/full_text.txt'.format(sets)\n",
    "    model = SentenceTransformer('../../tools/sbert-uncased-finnish-paraphrase')\n",
    "    sent_list = []\n",
    "    with open(input_text_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            sent_list.append(line.strip())\n",
    "        f.close()\n",
    "    sent_list = list(set(sent_list))\n",
    "    # tfidf_vect = TfidfVectorizer()\n",
    "    # tfidf = tfidf_vect.fit_transform(sent_list)\n",
    "    sent_vec = model.encode(sent_list)\n",
    "    pca = PCA(n_components=pca_dim)\n",
    "    reduced_fea = pca.fit_transform(sent_vec)\n",
    "    kmeans = KMeans(n_clusters=kmean_cluster).fit(reduced_fea)\n",
    "    \n",
    "    in_cluster_sample(sent_list, sets, kmeans, kmean_cluster, sample_per_cluster, reduced_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4378e0-7ea4-431f-a3fb-28976b45e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'KIR'\n",
    "pca_dim = 10\n",
    "kmean_cluster = 9\n",
    "sample_per_cluster = 25\n",
    "gen_sent_list(sets, pca_dim, kmean_cluster, sample_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cb914-d81e-472c-af6d-cbd1a2d36f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'LAH'\n",
    "pca_dim = 10\n",
    "kmean_cluster = 10\n",
    "sample_per_cluster = 20\n",
    "gen_sent_list(sets, pca_dim, kmean_cluster, sample_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9095eb0-9a16-4a34-9c2e-e84d346b1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'OPER'\n",
    "pca_dim = 5\n",
    "kmean_cluster = 9\n",
    "sample_per_cluster = 22\n",
    "gen_sent_list(sets, pca_dim, kmean_cluster, sample_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cac7d3-f9af-4c9c-8b35-027c3a66410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'RTG'\n",
    "pca_dim = 5\n",
    "kmean_cluster = 9\n",
    "sample_per_cluster = 18\n",
    "gen_sent_list(sets, pca_dim, kmean_cluster, sample_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97551b5b-1066-450e-b53a-a79fd73264a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = 'SAD'\n",
    "pca_dim = 5\n",
    "kmean_cluster = 8\n",
    "sample_per_cluster = 25\n",
    "gen_sent_list(sets, pca_dim, kmean_cluster, sample_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dade6f-b3ba-4105-b993-ddbdc1d6542b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
